{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d08a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:13:05.720845042Z",
     "start_time": "2023-12-11T12:13:05.635189606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful during development when helper functions may be updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31421aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:13:14.108555615Z",
     "start_time": "2023-12-11T12:13:06.414176046Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if not '../' in sys.path:\n",
    "    sys.path.append('../')\n",
    "\n",
    "from utils.utils import show_images\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "from utils.tiling import sliding_window_inference\n",
    "from utils.utils import save_image_with_label_overlay, _move_channel_axis, _choose_device, show_images\n",
    "from utils.utils import labels_to_features\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c8c680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:13:19.324393974Z",
     "start_time": "2023-12-11T12:13:18.321831279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model from torchscript\n",
    "instanseg = torch.jit.load(\"../torchscript_models/instanseg_1735176.pt\")\n",
    "model_pixel_size = instanseg.pixel_size\n",
    "\n",
    "device= _choose_device()\n",
    "\n",
    "instanseg.to(device)\n",
    "\n",
    "img = AICSImage(\"../examples/LuCa1.tif\")\n",
    "input_data = img.get_image_data(\"CYX\")\n",
    "\n",
    "#Set this to the pixel size in microns of the input image\n",
    "\n",
    "if img.physical_pixel_sizes.X is not None:\n",
    "    pixel_size = img.physical_pixel_sizes.X\n",
    "    print(\"Pixel size was found in the metadata, pixel size is set to: \", pixel_size)\n",
    "else:\n",
    "    pixel_size = 0.5\n",
    "    print(\"Pixel size was not found in the metadata, please set the pixel size of the input image in microns manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae7515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:13:24.884744465Z",
     "start_time": "2023-12-11T12:13:22.620576858Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.augmentations import Augmentations\n",
    "Augmenter=Augmentations()\n",
    "Augmenter.integer_channels_labels=[2,2] #You don't have to worry about this line\n",
    "\n",
    "input_tensor,_ =Augmenter.to_tensor(input_data,normalize=False) #this converts the input data to a tensor and does percentile normalization (no clipping)\n",
    "\n",
    "input_tensor,_ = Augmenter.normalize(input_tensor, percentile=0.)\n",
    "\n",
    "original_shape = input_tensor.shape[1:]\n",
    "\n",
    "\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904a6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:13:29.722243406Z",
     "start_time": "2023-12-11T12:13:29.481469035Z"
    }
   },
   "outputs": [],
   "source": [
    "#This rescales the input to the requested pixel size (0.5 microns).\n",
    "#For display purposes only\n",
    "input_tensor_to_rgb,_ = Augmenter.colourize(input_tensor,c_nuclei=6, random_seed = 1) # c_nuclei is the index of the nucleus channel in the input (nucleus channel is in blue by default in the display image)\n",
    "\n",
    "\n",
    "input_crop,_ = Augmenter.torch_rescale(input_tensor,labels=None,current_pixel_size=pixel_size,requested_pixel_size=model_pixel_size,crop = True, random_seed=1)\n",
    "input_tensor,_ = Augmenter.torch_rescale(input_tensor,labels=None,current_pixel_size=pixel_size,requested_pixel_size=model_pixel_size,crop = False, random_seed=1)\n",
    "input_crop_to_rgb,_ = Augmenter.colourize(input_crop,c_nuclei=6, random_seed = 1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2245d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:13:33.126387902Z",
     "start_time": "2023-12-11T12:13:31.883761177Z"
    }
   },
   "outputs": [],
   "source": [
    "# To run instanseg in one pass, you can simply call the model with the input tensor. (No tiling)\n",
    "\n",
    "#Make sure the input tensor is of shape 1, C, H, W.\n",
    "\n",
    "labeled_output = instanseg(input_crop.to(device)[None]) #The labeled_output shape should be 1,1,H,W (nucleus or whole cell) or 1,2,H,W (nucleus and whole cell)\n",
    "\n",
    "output_dimension = labeled_output.shape[1]\n",
    "\n",
    "print(labeled_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe962c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(input_tensor, dpi = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b34b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T12:13:41.400372485Z",
     "start_time": "2023-12-11T12:13:40.757128694Z"
    }
   },
   "outputs": [],
   "source": [
    "if output_dimension ==1: #Nucleus or cell mask]\n",
    "    show_images(input_crop_to_rgb,labeled_output[0,0],labels = [1],colorbar=False,titles= [\"Input (RGB Display)\",\"Predicted mask\"],dpi = 100)\n",
    "elif output_dimension ==2: #Nucleus and cell mask\n",
    "    show_images(input_crop_to_rgb,labeled_output[0,0],labeled_output[0,1],labels = [1,2],colorbar=True,titles= [\"Input (RGB Display)\",\"Predicted Nucleus mask\",\"Predicted Cell Mask\"],dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e39a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:40:40.318833354Z",
     "start_time": "2023-12-08T13:40:28.496463875Z"
    }
   },
   "outputs": [],
   "source": [
    "#This section actually calls the model and does the tiling in the background, it may take a few seconds to run\n",
    "\n",
    "tiled_labels = sliding_window_inference(input_tensor,instanseg, window_size = (512,512),overlap_size = 124/512,sw_device = device,device = 'cpu', output_channels = output_dimension)\n",
    "\n",
    "\n",
    "#Due to rounding errors, we have to normalize one more time, this should only change the size of the arrays by one pixel or so.\n",
    "input_tensor = torchvision.transforms.Resize(original_shape,interpolation = InterpolationMode.BILINEAR)(input_tensor)\n",
    "tiled_labels = torchvision.transforms.Resize(original_shape,interpolation = InterpolationMode.NEAREST)(tiled_labels)\n",
    "\n",
    "\n",
    "tiled_labels = tiled_labels\n",
    "print(tiled_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a81f3b2d110fc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:40:45.053792915Z",
     "start_time": "2023-12-08T13:40:44.835961079Z"
    }
   },
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "from utils.biological_utils import resolve_cell_and_nucleus_boundaries\n",
    "\n",
    "tiled_labels = resolve_cell_and_nucleus_boundaries(tiled_labels.to('cuda')).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abcbe4cb35a375f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:39:39.434935032Z",
     "start_time": "2023-12-08T13:39:38.809687333Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.pytorch_utils import torch_sparse_onehot, fast_sparse_dual_iou\n",
    "onehot1,_ = torch_sparse_onehot(tiled_labels[0,0],flatten=True)\n",
    "onehot2,_ = torch_sparse_onehot(tiled_labels[0,1],flatten=True)\n",
    "\n",
    "iou = fast_sparse_dual_iou(onehot1,onehot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f601b7355e96df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:39:44.943820095Z",
     "start_time": "2023-12-08T13:39:44.584332033Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "show_images(tiled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd62a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:39:49.204004261Z",
     "start_time": "2023-12-08T13:39:48.428387426Z"
    }
   },
   "outputs": [],
   "source": [
    "out_path = \"./Luca1_labels.geojson\"\n",
    "\n",
    "if output_dimension == 1:\n",
    "    features = labels_to_features(tiled_labels[0,0].numpy(),object_type = \"detection\")\n",
    "\n",
    "elif output_dimension == 2:\n",
    "    features = labels_to_features(tiled_labels[0,0].numpy(),object_type = \"detection\",classification=\"Nuclei\") + labels_to_features(tiled_labels[0,1].numpy(),object_type = \"detection\",classification = \"Cells\")\n",
    "geojson = json.dumps(features)\n",
    "with open(os.path.join(out_path), \"w\") as outfile:\n",
    "    outfile.write(geojson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aaca02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:39:50.023713563Z",
     "start_time": "2023-12-08T13:39:49.739644375Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if output_dimension ==1: #Nucleus or cell mask]\n",
    "    show_images(input_tensor_to_rgb,tiled_labels[0,0],labels = [1],colorbar=False,titles= [\"Input (RGB Display)\",\"Predicted mask\"],dpi = 100)\n",
    "elif output_dimension ==2: #Nucleus and cell mask\n",
    "    show_images(input_tensor_to_rgb,tiled_labels[0,0],tiled_labels[0,1],labels = [1,2],colorbar=False,titles= [\"Input (RGB Display)\",\"Predicted Nucleus mask\",\"Predicted Cell Mask\"],dpi = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9fab5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:40:45.944526495Z",
     "start_time": "2023-12-08T13:40:45.027283164Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "im_for_display = torch.clamp(input_tensor_to_rgb,0,1).cpu().numpy() * 255  #Shape is 3,H,W\n",
    "im_for_display = _move_channel_axis(im_for_display,to_back = True).astype(np.uint8) #Shape is H,W,3\n",
    "\n",
    "\n",
    "if output_dimension ==1: #Nucleus or cell mask]\n",
    "    labels_for_display = tiled_labels[0,0].cpu().numpy() #Shape is 1,H,W\n",
    "    image_overlay = save_image_with_label_overlay(im_for_display,lab=labels_for_display,return_image=True, label_boundary_mode=\"thick\", label_colors=None,thickness=10,alpha=0.5)\n",
    "elif output_dimension ==2: #Nucleus and cell mask\n",
    "    nuclei_labels_for_display = tiled_labels[0,0].cpu().numpy()\n",
    "    cell_labels_for_display = tiled_labels[0,1].cpu().numpy() #Shape is 1,H,W\n",
    "    image_overlay = save_image_with_label_overlay(im_for_display,lab=nuclei_labels_for_display,return_image=True, label_boundary_mode=\"thick\", label_colors=\"red\",thickness=10)\n",
    "    image_overlay = save_image_with_label_overlay(image_overlay,lab=cell_labels_for_display,return_image=True, label_boundary_mode=\"inner\", label_colors=\"green\",thickness=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1294b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:40:49.312341627Z",
     "start_time": "2023-12-08T13:40:49.209284333Z"
    }
   },
   "outputs": [],
   "source": [
    "show_images(image_overlay,colorbar=False,dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2f533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:49:15.468506479Z",
     "start_time": "2023-12-08T13:49:15.386050893Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now lets write everything as a single method:\n",
    "\n",
    "def run_instanseg(model_name: str,image_path, pixel_size: int = None, output_dir = None,  model_pixel_size=0.5, cell_and_nuclei=True, export_geojson: bool = True, number_of_input_channels = None):\n",
    "    from pathlib import Path\n",
    "    from utils.augmentations import Augmentations\n",
    "    import numpy as np\n",
    "    from aicsimageio import AICSImage\n",
    "    import warnings\n",
    "    from skimage import io\n",
    "\n",
    "    instanseg = torch.jit.load(Path(\"../examples/torchscript_models/\") / model_name)\n",
    "    device= _choose_device(verbose = False)\n",
    "    instanseg.to(device)\n",
    "    img = AICSImage(image_path)\n",
    "\n",
    "    if pixel_size is None and img.physical_pixel_sizes.X is None:\n",
    "        raise ValueError(\"Pixel size was not found in the metadata, please set the pixel size of the input image in microns manually\")\n",
    "    elif  pixel_size is None and img.physical_pixel_sizes.X is not None:\n",
    "        pixel_size = img.physical_pixel_sizes.X\n",
    "        assert pixel_size > 0 and pixel_size < 3, \"Pixel size is not in microns, please check the metadata\"\n",
    "        print(\"Pixel size was found in the metadata, pixel size is set to: \", pixel_size)\n",
    "\n",
    "    channel_number = img.dims.C\n",
    "    if \"S\" in img.dims.order and img.dims.S > img.dims.C:\n",
    "        channel_number = img.dims.S\n",
    "        input_data = img.get_image_data(\"SYX\")\n",
    "    else:\n",
    "        input_data = img.get_image_data(\"CYX\")\n",
    "\n",
    "    if number_of_input_channels is not None:\n",
    "        if channel_number != number_of_input_channels:\n",
    "            warnings.warn(\"Skipping images which don't fit the number of input channels of the model\")\n",
    "            return None\n",
    "    \n",
    "    Augmenter=Augmentations()\n",
    "\n",
    "    if cell_and_nuclei:\n",
    "        output_dimension=2\n",
    "        Augmenter.integer_channels_labels=[2,2]\n",
    "    else:\n",
    "        output_dimension=1\n",
    "        Augmenter.integer_channels_labels=[2] #You don't have to worry about this line\n",
    "\n",
    "    input_tensor,_ =Augmenter.to_tensor(input_data,normalize=True) #this converts the input data to a tensor and does percentile normalization (no clipping)\n",
    "\n",
    "   # show_images(input_tensor)\n",
    "    \n",
    "    \n",
    "    channel_number = input_tensor.shape[0]\n",
    "\n",
    "    input_tensor,_ = Augmenter.torch_rescale(input_tensor,labels=None,current_pixel_size=pixel_size,requested_pixel_size=model_pixel_size,crop = False, random_seed=1)\n",
    "\n",
    "    #For display purposes only\n",
    "    if channel_number !=3:\n",
    "        input_tensor_rendered,_ = Augmenter.colourize(input_tensor,c_nuclei=1, random_seed = 1) # c_nuclei is the index of the nucleus channel in the input (nucleus channel is in blue by default in the display image)\n",
    "    else:\n",
    "        input_tensor_rendered = input_tensor\n",
    "\n",
    "    #This section actually calls the model and does the tiling in the background, it may take a few seconds to run\n",
    "\n",
    "    tiled_labels = sliding_window_inference(input_tensor,instanseg, window_size = (512,512),overlap_size = 0.1,sw_device = device,device = 'cpu', output_channels = output_dimension)\n",
    "\n",
    "    #Recover the original pixel size\n",
    "    input_tensor_rendered,tiled_labels = Augmenter.torch_rescale(input_tensor_rendered,labels=tiled_labels.squeeze(0),current_pixel_size=model_pixel_size,requested_pixel_size=pixel_size,crop =False)\n",
    "    tiled_labels = tiled_labels.unsqueeze(0)\n",
    "    \n",
    "\n",
    "    if output_dir is None:\n",
    "        output_dir = Path(image_path).parent / (\"Results_\" + model_name)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        file_name= Path(image_path).stem\n",
    "\n",
    "        output_path = output_dir / file_name\n",
    "\n",
    "    if export_geojson:\n",
    "        if output_dimension == 1:\n",
    "            features = labels_to_features(tiled_labels[0,0].numpy(),object_type = \"detection\")\n",
    "\n",
    "        elif output_dimension == 2:\n",
    "            features = labels_to_features(tiled_labels[0,0].numpy(),object_type = \"detection\",classification=\"Nuclei\") + labels_to_features(tiled_labels[0,1].numpy(),object_type = \"detection\",classification = \"Cells\")\n",
    "        geojson = json.dumps(features)\n",
    "        with open(os.path.join(str(output_path) + \"_labels.geojson\" ), \"w\") as outfile:\n",
    "            outfile.write(geojson)\n",
    "\n",
    "    im_for_display = torch.clamp(input_tensor_rendered,0,1).cpu().numpy() * 255  #Shape is 3,H,W\n",
    "    im_for_display = _move_channel_axis(im_for_display,to_back = True).astype(np.uint8) #Shape is H,W,3\n",
    "\n",
    "\n",
    "    if output_dimension ==1: #Nucleus or cell mask]\n",
    "        labels_for_display = tiled_labels[0,0].cpu().numpy() #Shape is 1,H,W\n",
    "        image_overlay = save_image_with_label_overlay(im_for_display,lab=labels_for_display,return_image=True, label_boundary_mode=\"thick\", label_colors=None,thickness=5,alpha=1)\n",
    "    elif output_dimension ==2: #Nucleus and cell mask\n",
    "        nuclei_labels_for_display = tiled_labels[0,0].cpu().numpy()\n",
    "        cell_labels_for_display = tiled_labels[0,1].cpu().numpy() #Shape is 1,H,W\n",
    "        image_overlay = save_image_with_label_overlay(im_for_display,lab=nuclei_labels_for_display,return_image=True, label_boundary_mode=\"inner\", label_colors=\"red\",thickness=1)\n",
    "        image_overlay = save_image_with_label_overlay(image_overlay,lab=cell_labels_for_display,return_image=True, label_boundary_mode=\"inner\", label_colors=\"green\",thickness=1)\n",
    "\n",
    "\n",
    "    io.imsave(str(output_path) + \"_rendered_markup.tif\",image_overlay)\n",
    "    io.imsave(str(output_path) + \"_rendered.tif\",im_for_display)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aea96f52976e5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T14:14:32.306634753Z",
     "start_time": "2023-12-08T14:14:29.703844970Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.utils import export_to_torchscript\n",
    "\n",
    "export_to_torchscript(\"1740051\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735c3e59c596580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T13:52:30.067627845Z",
     "start_time": "2023-12-08T13:50:02.970424952Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "for image in tqdm(Path((\"../../Datasets/Unannotated/QBI_CROPS\")).iterdir()):\n",
    "    if \"Results\" not in str(image.name):\n",
    "        file = str(image.name)=\n",
    "        if file != \"Thumbs.db\":\n",
    "            run_instanseg(\"instanseg_1740051.pt\",image,pixel_size = None, model_pixel_size=0.5, cell_and_nuclei=True, export_geojson=False, number_of_input_channels = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45638f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_instanseg(\"instanseg_v0_2_0.pt\",\"/home/thibaut_goldsborough/Downloads/LuCa-7color_[17572,60173]_3x3component_data.tif\",pixel_size=0.5, model_pixel_size=0.5, cell_and_nuclei=True, export_geojson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03e5633e02f63b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae1f65caa71b38fc1ba7bd60417cf378993b2667a884a2b792dd708d4ac0a6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
